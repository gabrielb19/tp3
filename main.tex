\documentclass{article}
\usepackage{xcolor}
\usepackage{graphicx} % Required for inserting images
\usepackage{subcaption}
\usepackage{placeins}
\usepackage{float}
\usepackage{listings} 

\lstset{
    language=Python,
    backgroundcolor=\color{gray!10},
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    stringstyle=\color{red!60!black},
    commentstyle=\color{green!50!black}\itshape,
    showstringspaces=false,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray},
    breaklines=true,
    captionpos=b
}

\title{tarea_3_pdi}
\author{diegonm0207 }
\date{November 2025}

\usepackage[backend=biber,style=apa]{biblatex}
\addbibresource{bibliography.bib}

\begin{document}


\section{Entrenamiento base de ResNet, VGG16 y ViT}

\subsection{Metodología}

Como modelos a evaluar, se eligío utilizar ResNet, VGG16 y Vision Transformer (ViT) \cite{he2015deepresiduallearningimage} \cite{simonyan2015deepconvolutionalnetworkslargescale} \cite{dosovitskiy2021imageworth16x16words}. 

Se procedío a cargar el conjunto de datos \textit{Cataract-seg}, el cual consiste de 299 imágenes de fondo de ojo con fines tanto de segmentación como de clasificación de grados de severidad de catarata en el ojo, siendo los niveles ninguno, bajo y alto.

El conjunto de datos para el punto 1 se dividió entonces en las proporciones 80\% de los datos para el entrenamiento, 15\% de validación y, finalmente, un 5\% de test.

Se procedio a programar funciones para el cargado del conjunto de datos, el entrenamiento de los módelos y la instanciación de cada uno de los modelos previamente mencionados.

Después, se entrenó cada uno de los modelos durante 30 episodios, utilizando el algoritmo optimizador de \textit{Stochastic Gradient Descent}, con una tasa de aprendizaje de $0.001$ y con una función de pérdida \textit{Categorical Cross Entropy}.

Una vez entrenados los modelos, se genero la métrica f1, la mátriz de confusión y las curvas de la función de perdida a lo largo de las iteraciones.

\begin{lstlisting}[language=Python]
asd
\end{lstlisting}

\subsection{Resultados y Discusión}

\subsubsection{ResNet}

Como se puede observar en las curvas de training loss y validation loss \ref{fig:resnet_loss}, se observa un comportamiento donde con más iteraciones se reduce el valor de la función de perdida para el conjunto de entrenamiento y validación. Además, es posible observar como entre la epoca 1 a la 15, el módelo es donde más presenta cambios, mientras que de la epoca 15 a la 30, el cambio es muy reducido, pero viendose marcado por varios picos de error en el conjunto de entrenamiento.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{imgs/1_train_loss_resnet.png}
    \caption{Curvas del training loss y validation loss para el entrenamiento de la red ResNet sobre el conjunto de datos de cataratas.}
    \label{fig:resnet_loss}
\end{figure}

En cuanto a la matriz de confusión de la figura \ref{fig:resnet_confusion}, se observa un rendimiento muy alto al solo presentar un error en la clasifiación de un caso mild que fue catalogado como severe.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{imgs/1_confusion_matrix_resnet.png}
    \caption{Matriz de confusión para el conjunto de validación del modelo ResNet entrenado sobre el conjunto de datos de cataratas.}
    \label{fig:resnet_confusion}
\end{figure}

Al observar los resultados del f1 (ver tabla \ref{tab:resultados_f1}) entre los conjuntos de entrenamiento y validación, se puede observar que solo hay un leve deterioro en la métrica de f1, lo cual es esperable y demuestra que esta lograndose una adecuada generalización.

\subsection{VGG16}

Para VGG16, en la figura \ref{fig:vgg_loss} se puede observar en las curvas de training loss y validation loss \ref{fig:resnet_loss} repiten en cierta forma el comportamiento observado sobre ResNet, pero hay una diferencia entre los valores de perdida encontrados en el conjunto de entrenamiento y el conjunto de validación, siendo menores en el conjunto de validación, el de entrenamiento presentando los mismos picos observados previamente en ResNet.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{imgs/1_train_loss_vgg.png}
    \caption{Curvas del training loss y validation loss para el entrenamiento de la red VGG sobre el conjunto de datos de cataratas.}
    \label{fig:vgg_loss}
\end{figure}

Para la matríz de confusión de VGG16 presente en la figura \ref{fig:vgg_confusion}, no presenta ningún error de clasificación.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{imgs/1_confusion_matrix_vgg.png}
    \caption{Matriz de confusión para el conjunto de validación del modelo VGG entrenado sobre el conjunto de datos de cataratas.}
    \label{fig:vgg_confusion}
\end{figure}

Y en términos de rendimiento de la métrica f1, como se observa en la tabla \ref{tab:resultados_f1}, se obtuvo un valor de 0.9916 en el conjunto de entrenamiento y 1 en la validación, observándose que de nuevo, el modelo logró realizar una generalización adecuada, pero que la diferencia entre ResNet y VGG16 parece ser similar.

\subsubsection{ViT}

Con Visual Transformers, los valores de pérdida para el conjunto de entrenamiento y de validación, como se puede observar en la figura \ref{fig:vit_loss}, son los que presentan unas curvas más suaves y consistentes, ya que a diferencia de los otros modelos, no presentan picos tan marcados en el conjunto de entrenamiento.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{imgs/1_train_loss_vit.png}
    \caption{Curvas del training loss y validation loss para el entrenamiento de la red ViT sobre el conjunto de datos de cataratas.}
    \label{fig:vit_loss}
\end{figure}

Al observar la matríz de confusión en la figura \ref{fig:vit_confusion}, se puede observar que para el conjunto de entrenamiento, el módelo no presenta ningún error de clasificación.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\linewidth]{imgs/1_confusion_matrix_vit.png}
    \caption{Matriz de confusión para el conjunto de validación del modelo ViT entrenado sobre el conjunto de datos de cataratas.}
    \label{fig:vit_confusion}
\end{figure}

Por último, al observar el rendimiento entre las métricas de f1 (ver tabla \ref{tab:resultados_f1}) para el conjunto de entrenamiento y el de validación, ViT es el que posee un menor puntaje F1 ($0.9874$) comparado con los otros métodos, sin embargo sigue obteniendo un F1 de $1.0$

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\hline
\textbf{Modelo} & \textbf{F1 Train} & \textbf{F1 Validation} \\
\hline
ResNet & 0.9916 & 0.9774 \\
VGG    & 0.9916 & 1.0000 \\
ViT    & 0.9874 & 1.0000 \\
\hline
\end{tabular}
\caption{Resultados de F1-score para los modelos evaluados sobre el conjunto de datos de cataratas.}
\label{tab:resultados_f1}
\end{table}

\FloatBarrier

\section{Entrenamiento de modelos sobre 10 particiones.}

\subsection{Métodología}

Como modelos a evaluar, se repitieron ResNet, VGG16 y Vision Transformer (ViT) \cite{he2015deepresiduallearningimage} \cite{simonyan2015deepconvolutionalnetworkslargescale} \cite{dosovitskiy2021imageworth16x16words}. 

Se procedio a reutilizar tanto el conjunto de datos \textit{Cataract-seg}, como el código utilizado para cargarlo. Ahora el conjunto de datos se dividió entonces en las proporciones 70\% de los datos para el entrenamiento, 30\% de validación.

Después, se entrenó cada uno de los modelos durante 10 episodios, utilizando el algoritmo optimizador de \textit{Stochastic Gradient Descent}, con una tasa de aprendizaje de $0.001$ y con una función de pérdida \textit{Categorical Cross Entropy}.

Una vez entrenados los modelos sobre sus particiones correspondientes, se genero la métrica f1, la matriz de confusión y las curvas de la función de perdida a lo largo de las iteraciones.

Para realizar un procedimiento más controlado, se procedio a crear una clase encapsuladora llamada \textit{SplitsExperiment}, la cual coordina la instanciación, entrenamiento y reporte del performance de los modelos sobre las distintas particiones.

\subsection{Resultados y Discusión}

\subsubsection{Resnet}

Como se puede observar en la tabla \ref{tab:f1_resnet_splits}, inmediatamente se observa que hay un promedio más bajo que el observado en la tabla \ref{tab:resultados_f1} para ResNet, esto se atribuye a la diferencia de un 10\% de los datos tanto de entrenamiento como de evaluación, ya que en conjuntos de datos pequeños esa diferencia puede ser significativa. Aún así, se obtuvo un promedio alto de $0.9168$, con una desviación estándar $0.0244$, lo que puede sugerir que a pesar de estar trabajando sobre particiones distintas, el rendimiento es bastante consistente.

\begin{table}[H]
\centering
\begin{tabular}{l c}
\hline
\textbf{Split} & \textbf{F1-score} \\
\hline
Split 1  & 0.9324 \\
Split 2  & 0.9199 \\
Split 3  & 0.9081 \\
Split 4  & 0.8668 \\
Split 5  & 0.9205 \\
Split 6  & 0.9149 \\
Split 7  & 0.9163 \\
Split 8  & 0.9424 \\
Split 9  & 0.9577 \\
Split 10 & 0.8892 \\
\hline
\textbf{Promedio} & \textbf{0.9168} \\
\textbf{Desviación estándar} & \textbf{0.0244} \\
\hline
\end{tabular}
\caption{Resultados de F1-score para los 10 splits del modelo resnet.}
\label{tab:f1_resnet_splits}
\end{table}

Las curvas de pérdida en el entrenamiento y en el conjunto de validación (figura \ref{fig:resnet_train_val_splits}), demuestra el mismo comportamiento previamente observado de un descenso de los valores de perdida con respecto aumentan las épocas, demostrando que el modelo esta aprendiendo.

\begin{figure}[H]
    \centering

    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{imgs/2_train_resnet.png}
        \caption{Curvas de pérdida en el entrenamiento.}
        \label{fig:resnet_train_splits}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{imgs/2_loss_resnet.png}
        \caption{Curvas de pérdida en el conjunto de validación.}
        \label{fig:resnet_val_splits}
    \end{subfigure}

    \caption{Resultados de entrenamiento y pérdida del modelo ResNet sobre el conjunto de datos de cataratas.}
    \label{fig:resnet_train_val_splits}
\end{figure}

Al observar las matrices de confusión de los 10 modelos \ref{fig:2_matrix_resnet}, se puede observar que hay un error sistemático sobre la clasificación errónea en que donde se suelen equivocar, es que la clasificación \textit{mild} de catarata y la clase \textit{severe}, sin embargo, mayoritariamente se suele predecir la categoría correcta.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{imgs/2_matrix_resnet.png}
    \caption{Matriz de confusión para las particiones de ResNet}
    \label{fig:2_matrix_resnet}
\end{figure}

\FloatBarrier

\subsubsection{VGG16}

Observando el rendimiento en el puntaje F1, del conjunto de validación en la tabla \ref{tab:f1_splits_modelo2}, se obtuvo un promedio F1 de $0.8898$, con una desviación estándar de $0.0434$, presentando un promedio menor que el obtenido con Resnet, con una mayor dispersión, presentándose un modelo con valores cercanos a $0.8111$.

\begin{table}[h]
\centering
\begin{tabular}{l c}
\hline
\textbf{Split} & \textbf{F1-score} \\
\hline
Split 1  & 0.8551 \\
Split 2  & 0.8492 \\
Split 3  & 0.9202 \\
Split 4  & 0.9017 \\
Split 5  & 0.9539 \\
Split 6  & 0.8111 \\
Split 7  & 0.8967 \\
Split 8  & 0.8714 \\
Split 9  & 0.9542 \\
Split 10 & 0.8840 \\
\hline
\textbf{Promedio} & \textbf{0.8898} \\
\textbf{Desviación estándar} & \textbf{0.0434} \\
\hline
\end{tabular}
\caption{Resultados de F1-score para los 10 splits del modelo VGG.}
\label{tab:f1_splits_modelo2}
\end{table}

Al observar las curvas de la función de perdida (ver figura \ref{fig:resnet_train_val_splits}), se puede observar que si bien, el modelo seguía aprendiendo a lo largo de las épocas, el entrenamiento fue un proceso de descenso algo inestable, al poderse observar picos sobre la perdida del conjunto de entrenamiento, mientras que la perdida en el conjunto de validación resulto en un decrecimiento suave.


\begin{figure}[H]
    \centering

    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{imgs/2_train_vgg.png}
        \caption{Curvas de pérdida en el entrenamiento.}
        \label{fig:resnet_train_splits}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{imgs/2_loss_vgg.png}
        \caption{Curvas de pérdida en el conjunto de validación.}
        \label{fig:resnet_val_splits}
    \end{subfigure}

    \caption{Resultados de entrenamiento y pérdida del modelo VGG sobre el conjunto de datos de cataratas.}
    \label{fig:resnet_train_val_splits}
\end{figure}

Finalmente, al observar las matrices de confusión \ref{fig:2_matrix_vgg}, se puede ver como se repite el error sistemático entre las clases \textit{severe} y \textit{mild} a una escala mayor, pero existen algunos clasificadores los cuales tienen un problema adicional, aunque mínimo, de confundir la clas \textit{normal} con \textit{mild} y \textit{severe}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{imgs/2_matrix_vgg.png}
    \caption{Matriz de confusión para las particiones de VGG}
    \label{fig:2_matrix_vgg}
\end{figure}

\FloatBarrier
\subsubsection{Vit}

\begin{table}[h]
\centering
\begin{tabular}{l c}
\hline
\textbf{Split} & \textbf{F1-score} \\
\hline
Split 1  & 0.8380 \\
Split 2  & 0.8869 \\
Split 3  & 0.7945 \\
Split 4  & 0.7397 \\
Split 5  & 0.8321 \\
Split 6  & 0.8618 \\
Split 7  & 0.8739 \\
Split 8  & 0.6777 \\
Split 9  & 0.7807 \\
Split 10 & 0.6040 \\
\hline
\textbf{Promedio} & \textbf{0.7889} \\
\textbf{Desviación estándar} & \textbf{0.0869} \\
\hline
\end{tabular}
\caption{Resultados de F1-score para los 10 splits del modelo ViT.}
\label{tab:f1_splits_vit}
\end{table}

\begin{figure}[H]
    \centering

    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{imgs/2_train_vit.png}
        \caption{Curvas de pérdida en el entrenamiento.}
        \label{fig:vit_train_splits}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{imgs/2_loss_vit.png}
        \caption{Curvas de pérdida en el conjunto de validación.}
        \label{fig:vit_val_splits}
    \end{subfigure}

    \caption{Resultados de entrenamiento y pérdida del modelo ViT sobre el conjunto de datos de cataratas.}
    \label{fig:vit_train_val_splits}
\end{figure}

\section{Estimadores de incertidumbre}
\subsection{Feature Densities}
Para cada uno de los modelos, se extrajo su capa de embeddings, es decir, la que se encuentra antes de la clasificación. En el caso de los modelos \textbf{VGG} de \texttt{torchvision}, se selecciona la penúltima capa lineal del clasificador utilizando \texttt{model.classifier[5]}. Para \textbf{ResNet}, se extrae la capa de \textit{average pooling} (\texttt{model.avgpool}), que se encuentra justo antes de la capa totalmente conectada responsable de producir las clases. Finalmente, para \textit{Vision Transformer}, se utiliza la capa de normalización del \textit{encoder}.

Una vez extraída la capa de embeddings, para cada uno de los modelos, se extrajeron los feature-embeddings (activaciones de la capa de embeddings) para del dataset de entrenamiento. Para cada dimensión de la capa de embeddings se creó un histograma que almacenan, distribuidos en 20 bins, las activaciones de todas las imágenes del dataset de entrenamiento. Cada histograma posee un total de 20 bins, siguiendo la metodología utilizada por \cite{rodriguez2024uncertainty}. 

Dados los histogramas construidos con el conjunto de datos de entenamiento, se procede a estimar el valor de incertidumbre promedio del conjunto de datos de prueba en 4 configuraciones diferentes:
\begin{itemize}
    \item Limpio
    \item Con ruido gaussiano
    \item Con ruido salt and pepper
    \item Con reducción de resolución al 50\%
\end{itemize}

Al analizar los resultados de la Tabla~\ref{tab:density_scores}, se observa que, para todos los modelos, el dataset limpio obtuvo la menor puntuación de incertidumbre, lo cual es esperable dado que sus muestras provienen de la misma distribución utilizada durante el entrenamiento. 

Asimismo, los datasets con perturbaciones de ruido presentan las puntuaciones más altas, indicando que sus embeddings son los que más distan de las representaciones propias del dataset de entrenamiento. 

Finalmente, un resultado particularmente interesante es que los embeddings del dataset perturbado mediante reducción de resolución parecen ser relativamente similares a los del dataset limpio, lo que sugiere que el modelo no percibe esta perturbación como una desviación significativa dentro del espacio de embeddings.

\begin{table}[h!]
\centering
\caption{Promedio y desviación estándar de las estimaciones de incertidumbre de características bajo distintas perturbaciones.}
\label{tab:density_scores}
\begin{tabular}{lccc}
\hline
\textbf{Perturbación} & \textbf{VGG16} (mean $\pm$ std) & \textbf{ResNet50} (mean $\pm$ std) & \textbf{ViT-B16} (mean $\pm$ std) \\
\hline
Clean          & 22901.837 $\pm$ 595.894 & 282.386 $\pm$ 338.757 & 385.128 $\pm$ 92.638 \\
Gaussian       & 24829.499 $\pm$ 824.017 & 1129.616 $\pm$ 279.197 & 719.913 $\pm$ 106.601 \\
Salt \& Pepper & 26339.721 $\pm$ 248.555 & 1146.069 $\pm$ 224.096 & 673.119 $\pm$ 107.279 \\
Low Resolution & 22990.558 $\pm$ 344.050 & 565.159 $\pm$ 372.658 & 606.392 $\pm$ 81.646 \\
\hline
\end{tabular}
\end{table}

\subsection{Distancia de Jensen-Shannon}
\subsection{Deep Ensembles}
\subsection{Monte-Carlo dropout}
\subsection{Distancia de Mahalanobis}

\printbibliography
\end{document}
